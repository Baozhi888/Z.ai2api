# Z.ai2api API æ–‡æ¡£

## æ¦‚è¿°

Z.ai2api æä¾›äº†ä¸ OpenAI API å®Œå…¨å…¼å®¹çš„æ¥å£ï¼Œè®©å¼€å‘è€…å¯ä»¥è½»æ¾åœ°å°† Z.ai çš„èƒ½åŠ›é›†æˆåˆ°è‡ªå·±çš„åº”ç”¨ä¸­ã€‚

## åŸºç¡€ä¿¡æ¯

- **åŸºç¡€ URL**: `http://localhost:8080`
- **API ç‰ˆæœ¬**: v1
- **è®¤è¯æ–¹å¼**: Bearer Token
- **å†…å®¹ç±»å‹**: application/json

## è®¤è¯

æ‰€æœ‰ API è¯·æ±‚éƒ½éœ€è¦åœ¨è¯·æ±‚å¤´ä¸­åŒ…å«æœ‰æ•ˆçš„ API å¯†é’¥ï¼š

```http
Authorization: Bearer your-api-key
```

å¦‚æœæœªæä¾›æˆ– API å¯†é’¥æ— æ•ˆï¼Œå°†è¿”å› 401 é”™è¯¯ã€‚

## ç«¯ç‚¹åˆ—è¡¨

### 1. å¥åº·æ£€æŸ¥

æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œã€‚

**ç«¯ç‚¹**: `GET /health`

**è®¤è¯**: ä¸éœ€è¦

**å“åº”ç¤ºä¾‹**:
```json
{
  "status": "ok",
  "service": "Z.ai2api",
  "timestamp": "2024-01-01T12:00:00Z"
}
```

### 2. è·å–æ¨¡å‹åˆ—è¡¨

è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨ã€‚

**ç«¯ç‚¹**: `GET /v1/models`

**è®¤è¯**: éœ€è¦

**å“åº”ç¤ºä¾‹**:
```json
{
  "object": "list",
  "data": [
    {
      "id": "GLM-4.5",
      "object": "model",
      "created": 1640995200,
      "owned_by": "zai"
    },
    {
      "id": "GLM-4-Air",
      "object": "model",
      "created": 1640995200,
      "owned_by": "zai"
    }
  ]
}
```

### 3. åˆ›å»ºèŠå¤©å®Œæˆ

åˆ›å»ºä¸€ä¸ªæ–°çš„èŠå¤©å®Œæˆã€‚

**ç«¯ç‚¹**: `POST /v1/chat/completions`

**è®¤è¯**: éœ€è¦

**è¯·æ±‚å‚æ•°**:

| å‚æ•° | ç±»å‹ | å¿…éœ€ | è¯´æ˜ |
|------|------|------|------|
| `model` | string | æ˜¯ | è¦ä½¿ç”¨çš„æ¨¡å‹ ID |
| `messages` | array | æ˜¯ | æ¶ˆæ¯åˆ—è¡¨ |
| `stream` | boolean | å¦ | æ˜¯å¦ä½¿ç”¨æµå¼å“åº”ï¼Œé»˜è®¤ false |
| `temperature` | number | å¦ | æ¸©åº¦å‚æ•°ï¼Œ0-2ï¼Œé»˜è®¤ 0.7 |
| `max_tokens` | number | å¦ | æœ€å¤§ä»¤ç‰Œæ•° |
| `top_p` | number | å¦ | æ ¸é‡‡æ ·ï¼Œé»˜è®¤ 1 |
| `stop` | string/array | å¦ | åœæ­¢åºåˆ— |
| `presence_penalty` | number | å¦ | å­˜åœ¨æƒ©ç½šï¼Œé»˜è®¤ 0 |
| `frequency_penalty` | number | å¦ | é¢‘ç‡æƒ©ç½šï¼Œé»˜è®¤ 0 |

**æ¶ˆæ¯å¯¹è±¡æ ¼å¼**:

```json
{
  "role": "system|user|assistant",
  "content": "æ¶ˆæ¯å†…å®¹"
}
```

**è¯·æ±‚ç¤ºä¾‹**:
```json
{
  "model": "GLM-4.5",
  "messages": [
    {
      "role": "system",
      "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ã€‚"
    },
    {
      "role": "user",
      "content": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ã€‚"
    }
  ],
  "temperature": 0.7,
  "max_tokens": 1000
}
```

**å“åº”ç¤ºä¾‹** (éæµå¼):
```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1640995200,
  "model": "GLM-4.5",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›é€ èƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿ..."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 25,
    "completion_tokens": 150,
    "total_tokens": 175
  }
}
```

### 4. æµå¼èŠå¤©å®Œæˆ

åˆ›å»ºæµå¼èŠå¤©å®Œæˆï¼Œå®æ—¶æ¥æ”¶å“åº”ã€‚

**ç«¯ç‚¹**: `POST /v1/chat/completions`

**è®¤è¯**: éœ€è¦

**è¯·æ±‚å‚æ•°**: ä¸æ™®é€šèŠå¤©å®Œæˆç›¸åŒï¼Œä½† `stream` å¿…é¡»è®¾ä¸º `true`ã€‚

**è¯·æ±‚ç¤ºä¾‹**:
```json
{
  "model": "GLM-4.5",
  "messages": [
    {
      "role": "user",
      "content": "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—"
    }
  ],
  "stream": true
}
```

**æµå¼å“åº”æ ¼å¼**:

```http
data: {"id": "chatcmpl-abc123", "object": "chat.completion.chunk", "created": 1640995200, "model": "GLM-4.5", "choices": [{"index": 0, "delta": {"role": "assistant"}, "finish_reason": null}]}

data: {"id": "chatcmpl-abc123", "object": "chat.completion.chunk", "created": 1640995200, "model": "GLM-4.5", "choices": [{"index": 0, "delta": {"content": "æ˜¥"}, "finish_reason": null}]}

data: {"id": "chatcmpl-abc123", "object": "chat.completion.chunk", "created": 1640995200, "model": "GLM-4.5", "choices": [{"index": 0, "delta": {"content": "å¤©"}, "finish_reason": null}]}

...

data: {"id": "chatcmpl-abc123", "object": "chat.completion.chunk", "created": 1640995200, "model": "GLM-4.5", "choices": [{"index": 0, "delta": {}, "finish_reason": "stop"}]}

data: [DONE]
```

### 5. æ€§èƒ½æŒ‡æ ‡

è·å–æœåŠ¡æ€§èƒ½æŒ‡æ ‡ã€‚

**ç«¯ç‚¹**: `GET /metrics`

**è®¤è¯**: éœ€è¦

**å“åº”ç¤ºä¾‹**:
```json
{
  "uptime": 3600,
  "requests_total": 1000,
  "requests_per_second": 0.28,
  "cache_stats": {
    "hits": 800,
    "misses": 200,
    "hit_rate": 0.8,
    "size": 150
  },
  "memory_usage": {
    "rss": 67108864,
    "vms": 134217728
  },
  "cpu_usage": 0.05
}
```

## é”™è¯¯å¤„ç†

æ‰€æœ‰é”™è¯¯å“åº”éƒ½éµå¾ª OpenAI API æ ¼å¼ï¼š

```json
{
  "error": {
    "message": "é”™è¯¯æè¿°ä¿¡æ¯",
    "type": "error_type",
    "code": "error_code",
    "param": null
  }
}
```

### å¸¸è§é”™è¯¯ç 

| HTTP çŠ¶æ€ç  | é”™è¯¯ç±»å‹ | è¯´æ˜ |
|------------|----------|------|
| 400 | invalid_request_error | è¯·æ±‚æ ¼å¼é”™è¯¯æˆ–å‚æ•°æ— æ•ˆ |
| 401 | invalid_api_key | API å¯†é’¥æ— æ•ˆæˆ–ç¼ºå¤± |
| 403 | insufficient_permissions | æƒé™ä¸è¶³ |
| 404 | not_found | è¯·æ±‚çš„èµ„æºä¸å­˜åœ¨ |
| 429 | rate_limit_exceeded | è¯·æ±‚é¢‘ç‡è¶…é™ |
| 500 | server_error | æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ |
| 502 | upstream_error | ä¸Šæ¸¸æœåŠ¡é”™è¯¯ |
| 503 | service_unavailable | æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ |

### é”™è¯¯ç¤ºä¾‹

```json
{
  "error": {
    "message": "Invalid API key. Please check your API key and try again.",
    "type": "invalid_api_key",
    "code": "invalid_api_key"
  }
}
```

## è¯·æ±‚é™åˆ¶

- **æœ€å¤§å¹¶å‘è¯·æ±‚æ•°**: 100ï¼ˆå¯é…ç½®ï¼‰
- **è¯·æ±‚è¶…æ—¶æ—¶é—´**: 60 ç§’ï¼ˆå¯é…ç½®ï¼‰
- **æµå¼å“åº”è¶…æ—¶**: 120 ç§’ï¼ˆå¯é…ç½®ï¼‰
- **æœ€å¤§ä»¤ç‰Œæ•°**: æ ¹æ®æ¨¡å‹è€Œå®š

## æ€è€ƒé“¾å¤„ç†

Z.ai2api æ”¯æŒä¸‰ç§æ€è€ƒé“¾å¤„ç†æ¨¡å¼ï¼Œé€šè¿‡ `ZAI_THINK_TAGS_MODE` ç¯å¢ƒå˜é‡é…ç½®ï¼š

### 1. think æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰

å°†æ€è€ƒå†…å®¹è½¬æ¢ä¸ºå‹å¥½çš„æ ¼å¼ï¼š

```json
{
  "choices": [
    {
      "message": {
        "content": "ğŸ¤”\n\nç”¨æˆ·æƒ³è¦äº†è§£äººå·¥æ™ºèƒ½...\n\näººå·¥æ™ºèƒ½æ˜¯..."
      }
    }
  ]
}
```

### 2. pure æ¨¡å¼

ä¿ç•™åŸå§‹å¼•ç”¨æ ¼å¼ï¼š

```json
{
  "choices": [
    {
      "message": {
        "content": "> ç”¨æˆ·æƒ³è¦äº†è§£äººå·¥æ™ºèƒ½...\n\näººå·¥æ™ºèƒ½æ˜¯..."
      }
    }
  ]
}
```

### 3. raw æ¨¡å¼

å®Œæ•´çš„ HTML æ€è€ƒé“¾å±•ç¤ºï¼š

```json
{
  "choices": [
    {
      "message": {
        "content": "<details type=\"reasoning\" open><div>\n\nç”¨æˆ·æƒ³è¦äº†è§£äººå·¥æ™ºèƒ½...\n\n</div><summary>Thought for 1 seconds</summary></details>\n\näººå·¥æ™ºèƒ½æ˜¯..."
      }
    }
  ]
}
```

## ä½¿ç”¨ç¤ºä¾‹

### Python

```python
import requests
import json

# é…ç½®
API_URL = "http://localhost:8080/v1/chat/completions"
API_KEY = "your-api-key"

# è¯·æ±‚å¤´
headers = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}

# è¯·æ±‚æ•°æ®
data = {
    "model": "GLM-4.5",
    "messages": [
        {"role": "user", "content": "ä½ å¥½ï¼"}
    ]
}

# å‘é€è¯·æ±‚
response = requests.post(API_URL, headers=headers, json=data)
result = response.json()

print(result["choices"][0]["message"]["content"])
```

### æµå¼å“åº”ï¼ˆPythonï¼‰

```python
import requests

API_URL = "http://localhost:8080/v1/chat/completions"
API_KEY = "your-api-key"

headers = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}

data = {
    "model": "GLM-4.5",
    "messages": [
        {"role": "user", "content": "è®²ä¸ªæ•…äº‹"}
    ],
    "stream": True
}

response = requests.post(API_URL, headers=headers, json=data, stream=True)

for line in response.iter_lines():
    if line:
        line = line.decode('utf-8')
        if line.startswith("data: "):
            data = line[6:]
            if data == "[DONE]":
                break
            try:
                chunk = json.loads(data)
                content = chunk["choices"][0]["delta"].get("content", "")
                print(content, end="", flush=True)
            except:
                pass
```

### cURL

```bash
# æ™®é€šè¯·æ±‚
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Authorization: Bearer your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "GLM-4.5",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'

# æµå¼è¯·æ±‚
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Authorization: Bearer your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "GLM-4.5",
    "messages": [{"role": "user", "content": "Tell me a joke"}],
    "stream": true
  }'
```

### JavaScript (Fetch API)

```javascript
// æ™®é€šè¯·æ±‚
async function chat(message) {
  const response = await fetch('http://localhost:8080/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer your-api-key',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'GLM-4.5',
      messages: [{ role: 'user', content: message }]
    })
  });
  
  const data = await response.json();
  return data.choices[0].message.content;
}

// æµå¼è¯·æ±‚
async function streamChat(message) {
  const response = await fetch('http://localhost:8080/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer your-api-key',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'GLM-4.5',
      messages: [{ role: 'user', content: message }],
      stream: true
    })
  });
  
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    const chunk = decoder.decode(value);
    const lines = chunk.split('\n');
    
    for (const line of lines) {
      if (line.startsWith('data: ')) {
        const data = line.slice(6);
        if (data === '[DONE]') return;
        
        try {
          const parsed = JSON.parse(data);
          const content = parsed.choices[0].delta.content || '';
          process.stdout.write(content);
        } catch (e) {
          // å¿½ç•¥è§£æé”™è¯¯
        }
      }
    }
  }
}
```

## æœ€ä½³å®è·µ

1. **é”™è¯¯å¤„ç†**: å§‹ç»ˆæ£€æŸ¥å“åº”çŠ¶æ€ç å¹¶å¦¥å–„å¤„ç†é”™è¯¯
2. **é‡è¯•æœºåˆ¶**: å¯¹äº 5xx é”™è¯¯ï¼Œå®ç°æŒ‡æ•°é€€é¿é‡è¯•
3. **æµå¼å“åº”**: å¯¹äºé•¿æ–‡æœ¬ç”Ÿæˆï¼Œä½¿ç”¨æµå¼å“åº”æå‡ç”¨æˆ·ä½“éªŒ
4. **ä»¤ç‰Œç®¡ç†**: ç›‘æ§ä½¿ç”¨é‡ï¼Œé¿å…è¶…å‡ºé™åˆ¶
5. **ç¼“å­˜åˆ©ç”¨**: é‡å¤çš„è¯·æ±‚å¯ä»¥åˆ©ç”¨ç¼“å­˜æé«˜æ€§èƒ½

## SDK å…¼å®¹æ€§

Z.ai2api å®Œå…¨å…¼å®¹ OpenAI çš„ SDKï¼Œä½ å¯ä»¥ç›´æ¥ä½¿ç”¨ OpenAI çš„å®˜æ–¹ SDKï¼š

### OpenAI Python SDK

```python
from openai import OpenAI

client = OpenAI(
    api_key="your-api-key",
    base_url="http://localhost:8080/v1"
)

response = client.chat.completions.create(
    model="GLM-4.5",
    messages=[
        {"role": "user", "content": "Hello!"}
    ]
)

print(response.choices[0].message.content)
```

### OpenAI Node.js SDK

```javascript
const OpenAI = require('openai');

const openai = new OpenAI({
  apiKey: 'your-api-key',
  baseURL: 'http://localhost:8080/v1'
});

async function main() {
  const completion = await openai.chat.completions.create({
    model: 'GLM-4.5',
    messages: [{ role: 'user', content: 'Hello!' }]
  });
  
  console.log(completion.choices[0].message.content);
}

main();
```

## æ›´æ–°æ—¥å¿—

API çš„æ›´æ–°å°†é€šè¿‡ç‰ˆæœ¬å·å’Œå˜æ›´æ—¥å¿—è¿›è¡Œç®¡ç†ã€‚è¯·å…³æ³¨é¡¹ç›®çš„ releases é¡µé¢è·å–æœ€æ–°æ›´æ–°ã€‚